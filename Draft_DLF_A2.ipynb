{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs for image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training data augmentation and normalization\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Define test data normalization\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Load the CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Download and load training data\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_train\n",
    ")\n",
    "\n",
    "# Download and load test data\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Split train dataset into training and validation sets\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoader for train, validation, and test datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Verify Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to unnormalize, clip, and show an image\n",
    "def imshow(img):\n",
    "    img = img * 0.2023 + 0.4914  # Unnormalize using the mean and std deviation\n",
    "    img = torch.clamp(img, 0, 1)  # Clip the values to be within [0, 1]\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Define CIFAR-10 classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Display images with labels\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 2))\n",
    "for idx, ax in enumerate(axes):\n",
    "    img = images[idx] / 2 + 0.5  # Unnormalize\n",
    "    img = torch.clamp(img, 0, 1)  # Clip the values to be within [0, 1]\n",
    "    npimg = img.numpy()\n",
    "    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    ax.set_title(classes[labels[idx]])\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition – Implementing ResNet-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom ResNet-18 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class CustomResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomResNet18, self).__init__()\n",
    "        # Load ResNet-18 architecture\n",
    "        self.model = models.resnet18(pretrained=False)\n",
    "        \n",
    "        # Modify the initial convolution layer to fit CIFAR-10's image size\n",
    "        self.model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        # Remove max-pooling to avoid excessive downsampling for smaller images\n",
    "        self.model.maxpool = nn.Identity()\n",
    "        \n",
    "        # Modify the final fully connected layer to match the number of CIFAR-10 classes\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Instantiate the model\n",
    "resnet18_model = CustomResNet18(num_classes=10)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18_model = resnet18_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer (SGD with momentum)\n",
    "optimizer = optim.SGD(resnet18_model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.7856, Accuracy: 33.52%\n",
      "Epoch [2/20], Loss: 1.3850, Accuracy: 49.81%\n",
      "Epoch [3/20], Loss: 1.1527, Accuracy: 58.83%\n",
      "Epoch [4/20], Loss: 0.9876, Accuracy: 65.03%\n",
      "Epoch [5/20], Loss: 0.8900, Accuracy: 68.64%\n",
      "Epoch [6/20], Loss: 0.8070, Accuracy: 71.77%\n",
      "Epoch [7/20], Loss: 0.7495, Accuracy: 73.86%\n",
      "Epoch [8/20], Loss: 0.7075, Accuracy: 75.21%\n",
      "Epoch [9/20], Loss: 0.6564, Accuracy: 77.01%\n",
      "Epoch [10/20], Loss: 0.6218, Accuracy: 78.36%\n",
      "Epoch [11/20], Loss: 0.5941, Accuracy: 79.30%\n",
      "Epoch [12/20], Loss: 0.5703, Accuracy: 80.01%\n",
      "Epoch [13/20], Loss: 0.5416, Accuracy: 81.15%\n",
      "Epoch [14/20], Loss: 0.5183, Accuracy: 81.86%\n",
      "Epoch [15/20], Loss: 0.4950, Accuracy: 82.74%\n",
      "Epoch [16/20], Loss: 0.4837, Accuracy: 83.04%\n",
      "Epoch [17/20], Loss: 0.4640, Accuracy: 83.93%\n",
      "Epoch [18/20], Loss: 0.4499, Accuracy: 84.28%\n",
      "Epoch [19/20], Loss: 0.4341, Accuracy: 84.91%\n",
      "Epoch [20/20], Loss: 0.4215, Accuracy: 85.21%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20  # Adjust as needed\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    resnet18_model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Training phase\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = resnet18_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track loss and accuracy\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Calculate and display training accuracy\n",
    "    train_acc = 100. * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "    # Validation phase (optional)\n",
    "    # You can add validation accuracy tracking here if desired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Validation Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.4026, Train Acc: 86.12%, Val Loss: 0.4997, Val Acc: 82.99%\n",
      "Epoch [2/20], Train Loss: 0.3980, Train Acc: 85.91%, Val Loss: 0.5192, Val Acc: 81.97%\n",
      "Epoch [3/20], Train Loss: 0.3880, Train Acc: 86.49%, Val Loss: 0.4936, Val Acc: 83.03%\n",
      "Epoch [4/20], Train Loss: 0.3658, Train Acc: 87.08%, Val Loss: 0.5266, Val Acc: 82.44%\n",
      "Epoch [5/20], Train Loss: 0.3657, Train Acc: 87.23%, Val Loss: 0.4944, Val Acc: 82.88%\n",
      "Epoch [6/20], Train Loss: 0.3515, Train Acc: 87.81%, Val Loss: 0.5312, Val Acc: 81.99%\n",
      "Epoch [7/20], Train Loss: 0.3455, Train Acc: 87.90%, Val Loss: 0.4713, Val Acc: 83.88%\n",
      "Epoch [8/20], Train Loss: 0.3341, Train Acc: 88.16%, Val Loss: 0.5041, Val Acc: 83.12%\n",
      "Epoch [9/20], Train Loss: 0.3269, Train Acc: 88.69%, Val Loss: 0.4837, Val Acc: 83.29%\n",
      "Epoch [10/20], Train Loss: 0.3168, Train Acc: 88.91%, Val Loss: 0.4615, Val Acc: 84.06%\n",
      "Epoch [11/20], Train Loss: 0.3150, Train Acc: 88.94%, Val Loss: 0.4315, Val Acc: 85.15%\n",
      "Epoch [12/20], Train Loss: 0.3049, Train Acc: 89.23%, Val Loss: 0.4604, Val Acc: 84.68%\n",
      "Epoch [13/20], Train Loss: 0.2898, Train Acc: 89.92%, Val Loss: 0.4566, Val Acc: 84.87%\n",
      "Epoch [14/20], Train Loss: 0.2884, Train Acc: 89.74%, Val Loss: 0.4878, Val Acc: 83.75%\n",
      "Epoch [15/20], Train Loss: 0.2881, Train Acc: 89.72%, Val Loss: 0.4381, Val Acc: 85.62%\n",
      "Epoch [16/20], Train Loss: 0.2753, Train Acc: 90.30%, Val Loss: 0.4685, Val Acc: 84.50%\n",
      "Epoch [17/20], Train Loss: 0.2682, Train Acc: 90.50%, Val Loss: 0.4618, Val Acc: 85.03%\n",
      "Epoch [18/20], Train Loss: 0.2653, Train Acc: 90.76%, Val Loss: 0.4945, Val Acc: 83.74%\n",
      "Epoch [19/20], Train Loss: 0.2630, Train Acc: 90.64%, Val Loss: 0.4451, Val Acc: 84.77%\n",
      "Epoch [20/20], Train Loss: 0.2541, Train Acc: 91.12%, Val Loss: 0.4045, Val Acc: 86.28%\n"
     ]
    }
   ],
   "source": [
    "# Training loop with validation phase\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    resnet18_model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = resnet18_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track training loss and accuracy\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100. * correct / total\n",
    "\n",
    "    # Validation phase\n",
    "    resnet18_model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = resnet18_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    val_acc = 100. * correct / total\n",
    "\n",
    "    # Display results for current epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 88.99%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "resnet18_model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = resnet18_model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100. * correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.2: AlexNet Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomAlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomAlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  # Adjusted kernel size and stride\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Adjusted to prevent collapse\n",
    "\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Adjusted classifier to handle reduced spatial dimensions\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 4 * 4, 4096),  # Adjusted for CIFAR-10 image size\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the feature map\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "alexnet_model = CustomAlexNet(num_classes=10)\n",
    "\n",
    "# Move model to GPU if available\n",
    "alexnet_model = alexnet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer for AlexNet (SGD with momentum)\n",
    "optimizer = optim.SGD(alexnet_model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 2.2248, Train Acc: 15.43%, Val Loss: 2.0449, Val Acc: 25.09%\n",
      "Epoch [2/20], Train Loss: 1.9206, Train Acc: 27.68%, Val Loss: 1.7676, Val Acc: 33.21%\n",
      "Epoch [3/20], Train Loss: 1.7289, Train Acc: 35.42%, Val Loss: 1.6051, Val Acc: 40.91%\n",
      "Epoch [4/20], Train Loss: 1.5907, Train Acc: 40.62%, Val Loss: 1.4863, Val Acc: 45.80%\n",
      "Epoch [5/20], Train Loss: 1.4689, Train Acc: 45.73%, Val Loss: 1.3830, Val Acc: 49.33%\n",
      "Epoch [6/20], Train Loss: 1.3462, Train Acc: 50.63%, Val Loss: 1.2210, Val Acc: 55.99%\n",
      "Epoch [7/20], Train Loss: 1.2563, Train Acc: 54.24%, Val Loss: 1.1677, Val Acc: 57.35%\n",
      "Epoch [8/20], Train Loss: 1.1721, Train Acc: 57.83%, Val Loss: 1.1778, Val Acc: 58.31%\n",
      "Epoch [9/20], Train Loss: 1.1006, Train Acc: 60.20%, Val Loss: 1.0236, Val Acc: 63.01%\n",
      "Epoch [10/20], Train Loss: 1.0319, Train Acc: 62.96%, Val Loss: 0.9741, Val Acc: 65.27%\n",
      "Epoch [11/20], Train Loss: 0.9717, Train Acc: 65.53%, Val Loss: 0.9408, Val Acc: 66.69%\n",
      "Epoch [12/20], Train Loss: 0.9405, Train Acc: 66.85%, Val Loss: 0.9162, Val Acc: 67.57%\n",
      "Epoch [13/20], Train Loss: 0.8964, Train Acc: 68.25%, Val Loss: 0.8460, Val Acc: 69.88%\n",
      "Epoch [14/20], Train Loss: 0.8682, Train Acc: 69.40%, Val Loss: 0.8491, Val Acc: 70.32%\n",
      "Epoch [15/20], Train Loss: 0.8236, Train Acc: 70.97%, Val Loss: 0.8126, Val Acc: 71.09%\n",
      "Epoch [16/20], Train Loss: 0.7898, Train Acc: 72.42%, Val Loss: 0.7666, Val Acc: 73.25%\n",
      "Epoch [17/20], Train Loss: 0.7636, Train Acc: 73.42%, Val Loss: 0.7751, Val Acc: 72.62%\n",
      "Epoch [18/20], Train Loss: 0.7345, Train Acc: 74.48%, Val Loss: 0.7299, Val Acc: 74.58%\n",
      "Epoch [19/20], Train Loss: 0.7083, Train Acc: 75.27%, Val Loss: 0.7555, Val Acc: 73.67%\n",
      "Epoch [20/20], Train Loss: 0.6947, Train Acc: 76.16%, Val Loss: 0.7208, Val Acc: 74.85%\n"
     ]
    }
   ],
   "source": [
    "# Training loop with validation for AlexNet\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    alexnet_model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = alexnet_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track training loss and accuracy\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100. * correct / total\n",
    "\n",
    "    # Validation phase\n",
    "    alexnet_model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = alexnet_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    val_acc = 100. * correct / total\n",
    "\n",
    "    # Display results for current epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Phase for AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for AlexNet: 78.21%\n"
     ]
    }
   ],
   "source": [
    "# Test the AlexNet model\n",
    "alexnet_model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = alexnet_model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100. * correct / total\n",
    "print(f\"Test Accuracy for AlexNet: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3: MobileNetV2 Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /Users/chayonimeu/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
      "100%|██████████| 13.6M/13.6M [00:01<00:00, 12.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "class CustomMobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomMobileNetV2, self).__init__()\n",
    "        # Load MobileNetV2 with pretrained weights\n",
    "        self.model = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "        # Modify the classifier layer for CIFAR-10\n",
    "        self.model.classifier[1] = nn.Linear(self.model.classifier[1].in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Instantiate the model\n",
    "mobilenet_model = CustomMobileNetV2(num_classes=10)\n",
    "\n",
    "# Move model to GPU if available\n",
    "mobilenet_model = mobilenet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer for MobileNetV2 (SGD with momentum)\n",
    "optimizer = optim.SGD(mobilenet_model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 1.5022, Train Acc: 47.02%, Val Loss: 1.2025, Val Acc: 56.61%\n",
      "Epoch [2/20], Train Loss: 1.1125, Train Acc: 61.12%, Val Loss: 1.0168, Val Acc: 63.97%\n",
      "Epoch [3/20], Train Loss: 0.9959, Train Acc: 65.20%, Val Loss: 1.0140, Val Acc: 64.10%\n",
      "Epoch [4/20], Train Loss: 0.9392, Train Acc: 67.58%, Val Loss: 0.8851, Val Acc: 68.90%\n",
      "Epoch [5/20], Train Loss: 0.8670, Train Acc: 69.88%, Val Loss: 0.8363, Val Acc: 70.72%\n",
      "Epoch [6/20], Train Loss: 0.8303, Train Acc: 71.27%, Val Loss: 0.8308, Val Acc: 70.67%\n",
      "Epoch [7/20], Train Loss: 0.7914, Train Acc: 72.36%, Val Loss: 0.8094, Val Acc: 71.29%\n",
      "Epoch [8/20], Train Loss: 0.8069, Train Acc: 71.92%, Val Loss: 0.7506, Val Acc: 73.59%\n",
      "Epoch [9/20], Train Loss: 0.7536, Train Acc: 73.83%, Val Loss: 0.7615, Val Acc: 73.47%\n",
      "Epoch [10/20], Train Loss: 0.7669, Train Acc: 73.42%, Val Loss: 0.7850, Val Acc: 72.60%\n",
      "Epoch [11/20], Train Loss: 0.7346, Train Acc: 74.61%, Val Loss: 0.7345, Val Acc: 74.12%\n",
      "Epoch [12/20], Train Loss: 0.7087, Train Acc: 75.34%, Val Loss: 0.7200, Val Acc: 74.54%\n",
      "Epoch [13/20], Train Loss: 0.7093, Train Acc: 75.43%, Val Loss: 0.7862, Val Acc: 72.45%\n",
      "Epoch [14/20], Train Loss: 0.6914, Train Acc: 75.73%, Val Loss: 0.7081, Val Acc: 75.15%\n",
      "Epoch [15/20], Train Loss: 0.6800, Train Acc: 76.61%, Val Loss: 0.6883, Val Acc: 75.82%\n",
      "Epoch [16/20], Train Loss: 0.6623, Train Acc: 77.16%, Val Loss: 0.6803, Val Acc: 75.93%\n",
      "Epoch [17/20], Train Loss: 0.6620, Train Acc: 76.95%, Val Loss: 0.7132, Val Acc: 74.95%\n",
      "Epoch [18/20], Train Loss: 0.6638, Train Acc: 76.85%, Val Loss: 0.9718, Val Acc: 67.09%\n",
      "Epoch [19/20], Train Loss: 1.6696, Train Acc: 39.76%, Val Loss: 1.4236, Val Acc: 48.69%\n",
      "Epoch [20/20], Train Loss: 1.2669, Train Acc: 54.63%, Val Loss: 1.1843, Val Acc: 57.93%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    mobilenet_model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = mobilenet_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track training loss and accuracy\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100. * correct / total\n",
    "\n",
    "    # Validation phase\n",
    "    mobilenet_model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = mobilenet_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    val_acc = 100. * correct / total\n",
    "\n",
    "    # Display results for current epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for MobileNetV2: 63.44%\n"
     ]
    }
   ],
   "source": [
    "# Test the MobileNetV2 model\n",
    "mobilenet_model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = mobilenet_model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100. * correct / total\n",
    "print(f\"Test Accuracy for MobileNetV2: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'running_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m train_accuracies, val_accuracies \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# After each epoch in the training loop, append losses and accuracies\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mrunning_loss\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader))\n\u001b[1;32m      7\u001b[0m val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(val_loader))\n\u001b[1;32m      8\u001b[0m train_accuracies\u001b[38;5;241m.\u001b[39mappend(train_acc)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'running_loss' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store results for each epoch\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "# After each epoch in the training loop, append losses and accuracies\n",
    "train_losses.append(running_loss / len(train_loader))\n",
    "val_losses.append(val_loss / len(val_loader))\n",
    "train_accuracies.append(train_acc)\n",
    "val_accuracies.append(val_acc)\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loss Curve\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "# Accuracy Curve\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation\n",
    "Will Cukierski. CIFAR-10 - Object Recognition in Images. https://kaggle.com/competitions/cifar-10, 2013. Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
